# -*- coding: utf-8 -*-
"""anime_recommender.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/111ZEFSgCpQMX734OgbzxsDNG_Zx7IkdM

# Laporan Proyek Machine Learning - Muhammad Bagus Adi Prayoga

## Project Review

Industri anime mengalami pertumbuhan pesat dalam beberapa tahun terakhir, didorong oleh popularitas platform streaming dan konten yang berlimpah. Dengan banyaknya judul anime yang tersedia, penonton sering kali kesulitan menemukan konten baru yang sesuai dengan selera mereka [1]. Di sinilah sistem rekomendasi anime berperan, memberikan saran personal berdasarkan preferensi pengguna dan karakteristik konten.

Ada beberapa alasan mengapa sistem rekomendasi sangat penting bagi industri anime:
- **Menavigasi Konten yang Beragam**: Pertumbuhan anime yang eksponensial dapat membuat penonton kewalahan dan kesulitan menemukan konten yang sesuai dengan minat mereka. Sistem rekomendasi membantu pengguna menemukan konten yang relevan dengan minat mereka.
- **Meningkatkan Kepuasan Pengguna**: Rekomendasi yang dipersonalisasi membantu pengguna menemukan konten yang mereka sukai, meningkatkan kepuasan dan keterlibatan dengan platform.
- **Mempertahankan Pengguna**: Sistem rekomendasi membantu platform mempertahankan pengguna dengan terus menyediakan konten sesuai preferensi mereka, mengurangi kemungkinan berpindah ke platform lain.

Penelitian sebelumnya pada sistem rekomendasi anime telah mengeksplorasi berbagai pendekatan dan teknik untuk meningkatkan akurasi dan efektivitas rekomendasi. Beberapa bidang penelitian utama yang telah dipelajari meliputi:
- ***Collaborative Filtering***: Pendekatan ini melibatkan analisis perilaku pengguna yang serupa untuk memberikan rekomendasi. Pendekatan ini terbukti efektif dalam memberikan rekomendasi berdasarkan kesamaan minat di antara para pengguna [2].
- ***Content-Based Filtering***: Metode ini berfokus pada karakteristik konten itu sendiri, seperti genre, sutradara, atau pengisi suara, untuk memberikan rekomendasi. Metode ini memungkinkan rekomendasi yang dipersonalisasi berdasarkan preferensi spesifik pengguna [2].

Singkatnya, pertumbuhan industri anime dan banyaknya konten yang tersedia mengharuskan penggunaan sistem rekomendasi untuk membantu penonton menemukan dan menikmati konten yang sesuai dengan preferensi mereka. Penelitian yang ada telah mengeksplorasi berbagai pendekatan dan teknik untuk meningkatkan efektivitas sistem ini, dengan fokus pada *collaborative filtering* dan *content-based filtering*.

## Business Understanding

### Problem Statements

Berdasarkan pemahaman atas *project overview* yang telah diuraikan sebelumnya, berikut adalah *problem statements* yang teridentifikasi:
1. Bagaimana membangun sistem rekomendasi anime yang efektif untuk membantu pengguna menemukan konten yang sesuai dengan informasi anime yang tersedia?
2. Bagaimana membangun sistem rekomendasi anime yang dapat memberikan rekomendasi berdasarkan kesamaan minat di antara pengguna?

### Goals

Berdasarkan *problem statements* yang telah diidentifikasi sebelumnya, berikut adalah beberapa *goals* dari proyek ini:
1. Mengembangkan sistem rekomendasi anime berdasarkan kesamaan informasi anime yang tersedia.
2. Mengembangkan sistem rekomendasi anime berdasarkan kesamaan penilaian anime yang diberikan oleh pengguna.

### Solution statements

Berdasarkan *goals* di atas, maka diperoleh beberapa *solution statement* untuk menyelesaikan masalah tersebut, yaitu:
1. Membuat sistem rekomendasi dengan teknik *Content-Based Filtering* berdasarkan informasi anime.
2. Membuat sistem rekomendasi dengan teknik *Collaborative Filtering* berdasarkan penilaian anime yang diberikan oleh pengguna.

## Data Understanding

### Colab Setup
"""

from google.colab import drive
drive.mount('/content/drive')

! pip -q install kaggle
! mkdir ~/.kaggle
! cp /content/drive/MyDrive/kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
! kaggle datasets download CooperUnion/anime-recommendations-database
! unzip anime-recommendations-database.zip

"""### Initial Setup"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# import anime data
anime = pd.read_csv("anime.csv", engine="pyarrow")
anime.head()

# import user rating data
rating = pd.read_csv("rating.csv", engine="pyarrow")
rating.head()

"""### Datasets Description

#### Anime Data
"""

# anime data columns info
anime.info(), anime.shape

# anime data descriptive statistics
anime.describe().T

# anime data descriptive statistics for object columns
anime.describe(include=object).T

# anime data missing values
anime.isna().sum()

# drop missing values
anime.dropna(axis=0, inplace=True)
anime.isna().sum()

# check duplicate value
anime[anime.duplicated()].shape

"""**Insight:**
- Tabel `anime.csv` terdiri dari 12,294 baris dan 6 kolom
- Pada kolom *episodes* terdapat indikasi ada nilai yang bukan bilangan bulat
- Terdapat *missing value* pada kolom rating, sehingga perlu dilakukan *missing value handling*
    - Dalam hal ini langsung dilakukan penghapusan data, karena data yang memiliki nilai tersebut sangat sedikit
- Tidak ada data duplikat pada tabel ini

#### Rating Data
"""

# rating data columns info
rating.info(), rating.shape

# rating data descriptive statistics
rating.describe().T.to_markdown()

# rating data missing values
rating.isna().sum()

# rating data duplicate
rating[rating.duplicated(["user_id", "anime_id"])].shape

# drop rating duplicated data
rating = rating.drop_duplicates(["user_id", "anime_id"])
rating[rating.duplicated(["user_id", "anime_id"])].shape

"""**Insight:**
- Tabel `rating.csv` terdiri dari 7,813,737 baris dan 3 kolom
- Tidak ada *missing value* pada tabel ini
- Terdapat data duplikat pada tabel ini, sehingga perlu dihapus

### Exploratory Data Analysis
"""

# merge kedua tabel
anime_rating = pd.merge(anime, rating, on="anime_id", suffixes=(None, "_user"))
anime_rating = anime_rating.rename(columns={"name": "anime_name", "rating_user": "user_rating"})
anime_rating.head()

"""#### Rating Distribution"""

# average rating (web rating) and user rating distribution
plt.figure(figsize=(20, 8))
plt.subplot(1, 2, 1)
sns.histplot(anime["rating"], kde=True, bins=20, alpha=1, fill=True)
plt.title("Average Rating Distribution")
plt.subplot(1, 2, 2)
sns.histplot(anime_rating["user_rating"], kde=True, bins=20, alpha=1, fill=True)
plt.title("User Rating Distribution")
plt.show()

"""**Insight**:
- Terdapat outlier pada user rating, dimana ada data rating yang bernilai -1, sehinnga perlu dilakukan cleaning pada data user rating.
- Data rata-rata rating terdistribusi normal

#### Top Anime Members
"""

df_temp = anime_rating.copy()
df_temp.drop_duplicates(subset=["anime_name"], inplace=True, keep="first")
top_anime_member = (
    df_temp.groupby("anime_name")
    ["members"].sum()
    .sort_values(ascending=False)
    .head(10)
)
top_anime_member

# top 10 anime with the most members
plt.figure(figsize=(10, 6))
sns.barplot(y=top_anime_member.index, x=top_anime_member.values, hue=top_anime_member.index, dodge=False)
plt.title("Top 10 Anime with the Most Members")
plt.xlabel("Total Members")
plt.ylabel("Anime Name")
plt.gca().xaxis.set_major_formatter(plt.matplotlib.ticker.StrMethodFormatter('{x:,.0f}'))
plt.show()

# plot anime members
plt.figure(figsize=(10, 8))
sns.histplot(anime["members"], kde=True, bins=100, alpha=1, fill=True)
plt.title("Anime Members Distribution")
plt.gca().xaxis.set_major_formatter(plt.matplotlib.ticker.StrMethodFormatter('{x:,.0f}'))
plt.show()

"""#### Top Anime Users Ratings"""

# top 10 anime with the highest sum of user rating
top_anime_user_rating = (
    anime_rating.groupby("anime_name")
    ["user_rating"].sum()
    .sort_values(ascending=False)
    .head(10)
)
top_anime_user_rating

plt.figure(figsize=(10, 6))
sns.barplot(y=top_anime_user_rating.index, x=top_anime_user_rating.values, hue=top_anime_user_rating.index, dodge=False)
plt.title("Top 10 Anime with the Highest User Rating")
plt.xlabel("Total User Rating (Sum)")
plt.ylabel("Anime Name")
plt.gca().xaxis.set_major_formatter(plt.matplotlib.ticker.StrMethodFormatter('{x:,.0f}'))
plt.show()

"""#### Anime Categories"""

top_anime_category = (
    df_temp.groupby("type")
    ["anime_name"].count()
    .sort_values(ascending=False)
)
top_anime_category

# plot anime category distribution
plt.figure(figsize=(8, 4))
sns.barplot(y=top_anime_category.index, x=top_anime_category.values, hue=top_anime_category.index, dodge=False)
plt.title("Anime Category Distribution")
plt.xlabel("Total Anime")
plt.ylabel("Anime Category")
plt.gca().xaxis.set_major_formatter(plt.matplotlib.ticker.StrMethodFormatter('{x:,.0f}'))
plt.show()

"""#### Anime Genres"""

from collections import defaultdict
from wordcloud import WordCloud

all_genres = defaultdict(int)

for genres in anime_rating["genre"]:
    for genre in genres.split(","):
        all_genres[genre.strip()] += 1

wordcloud = WordCloud(
    width=720,
    height=360,
    background_color="black",
    colormap="RdYlGn",
).generate_from_frequencies(all_genres)

plt.figure(figsize=(10, 8), facecolor="#ffd100")
plt.imshow(wordcloud)
plt.axis("off")
plt.margins(x=0, y=0)
plt.tight_layout(pad=0)
plt.show()

"""#### Anime Episodes"""

# anime episodes value unique
anime["episodes"].unique()

# plot anime episodes distribution
plt.figure(figsize=(20, 8))
sns.histplot(anime["episodes"], kde=True, bins=20, alpha=1, fill=True)
plt.title("Anime Episodes Distribution")
plt.xlabel("Total Episodes")
plt.ylabel("Total Anime")
plt.xticks(rotation=90)
plt.show()

"""**Insight**:
- Terdapat nilai `Unknown` pada jumlah episode anime, sehingga perlu dilakukan dilakukan handling data.

### Clear Variable
"""

# Commented out IPython magic to ensure Python compatibility.
# %reset -f

"""## Data Preparation

### Content Based Filtering
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# import anime data
df_anime = pd.read_csv("anime.csv")
df_anime.head()

# drop missing values
df_anime.dropna(axis=0, inplace=True)
df_anime.isna().sum()

"""#### Episodes Column Handling"""

# remove unknown values on episodes column
df_anime = df_anime[df_anime["episodes"] != "Unknown"]
df_anime["episodes"] = df_anime["episodes"].astype(int)
df_anime["episodes"].unique()

"""#### Genre and Type Column Handling"""

# Preprocess the genre data
## remove the leading and trailing whitespaces
df_anime["genre"] = df_anime["genre"].str.strip()
## replace the comma with space
df_anime["genre"] = df_anime["genre"].str.replace(",", " ")
## lower case the genre
df_anime["genre"] = df_anime["genre"].str.lower()

# Preprocess the type data
## lower case the type
df_anime["type"] = df_anime["type"].str.lower()

df_anime.head()

"""#### Encode Episodes, Rating, and Members"""

df_anime.describe().T

def encode_episodes(num_episodes):
    if num_episodes == 1:
        return "oneepisode"
    elif num_episodes < 14:
        return "shortepisode"
    elif num_episodes < 27:
        return "mediumepisode"
    elif num_episodes < 65:
        return "longepisode"
    elif num_episodes < 131:
        return "verylongepisode"
    elif num_episodes < 208:
        return "epicepisode"
    elif num_episodes < 500:
        return "legendaryepisode"
    else:
        return "neverendingepisode"

def encode_rating(rating):
    if rating < 2:
        return "verybad"
    elif rating < 4:
        return "bad"
    elif rating < 6:
        return "average"
    elif rating < 7:
        return "good"
    elif rating < 8:
        return "verygood"
    elif rating < 9:
        return "great"
    else:
        return "masterpiece"

def encode_popularity(member_count):
    if member_count < 50000:
        return "unpopular"
    elif member_count < 100000:
        return "lesspopular"
    elif member_count < 200000:
        return "popular"
    elif member_count < 400000:
        return "verypopular"
    elif member_count < 800000:
        return "famous"
    else:
        return "legendary"

# apply the encode function
df_anime["episodes_category"] = df_anime["episodes"].apply(encode_episodes)
df_anime["rating_category"] = df_anime["rating"].apply(encode_rating)
df_anime["popularity_category"] = df_anime["members"].apply(encode_popularity)
df_anime.head()

"""#### Make Features for Content Based Filtering"""

# combine the features based on the genre, type, episodes, rating, and popularity
df_anime["features"] = (
    df_anime["genre"]
    + " "
    + df_anime["type"]
    + " "
    + df_anime["episodes_category"]
    + " "
    + df_anime["rating_category"]
    + " "
    + df_anime["popularity_category"]
)
df_anime.head()

# reset index after preprocessing
df_anime.reset_index(inplace=True)

"""### Collaborative Filtering"""

df_rating = pd.read_csv("rating.csv")
df_rating.head()

df_rating.shape

# check rating with value -1
print(df_rating[df_rating["rating"] == -1].shape)

# check percentage of rating with value -1
print(df_rating[df_rating["rating"] == -1].shape[0] / df_rating.shape[0] * 100)

# drop rating with value -1
df_rating = df_rating[df_rating["rating"] != -1]
df_rating.shape

# check duplicate rating
print(df_rating[df_rating.duplicated()].shape)

# drop duplicate rating
df_rating = df_rating.drop_duplicates(["user_id", "anime_id"])
df_rating.shape

# check missing values
df_rating.isna().sum()

df_rating['user_id'].value_counts()

# limit dataset (limited memory used)
counts = df_rating['user_id'].value_counts()
df_rating = df_rating[df_rating['user_id'].isin(counts[counts >= 500].index)]

print(df_rating.shape)
df_rating.head()

df_anime_rating = pd.merge(df_anime, df_rating, on="anime_id", suffixes=(None, "_user"))
df_anime_rating = df_anime_rating.rename(columns={"name": "anime_name", "rating_user": "user_rating"})
df_anime_rating.head()

anime_pivot = df_anime_rating.pivot_table(index='anime_name',columns='user_id',values='user_rating').fillna(0)
anime_pivot.head()

"""## Modeling and Result

### Content Based Filtering

#### Cosine Similarity
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity


# Create TF-IDF matrix based on features
tfidf = TfidfVectorizer()

tfidf_matrix = tfidf.fit_transform(df_anime["features"])

# Compute cosine similarity
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

# check the shape of the matrix
tfidf_matrix.shape, cosine_sim.shape, tfidf.get_feature_names_out()

"""#### Helper Function for Content Based Filtering"""

def find_anime(title, anime_data):
    try:
        # Search for anime with the given title
        bool_series = anime_data["name"].str.contains(title, case=False, na=False)
        # Filter the dataframe based on the search result
        found_anime = anime_data[bool_series]
        return found_anime
    except:
        return "Anime not found or an error occurred."


def get_cbf_recommendations(title, cosine_sim=cosine_sim, anime_data=df_anime, n_anime=5):
    try:
        # Get the index of the anime title
        idx = anime_data.loc[anime_data["name"] == title].index[0]

        # Get the pairwise similarity scores
        sim_scores = list(enumerate(cosine_sim[idx]))

        # Sort the anime titles based on similarity scores
        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

        # Get the top N most similar anime titles (excluding the input title itself)
        top_anime_indices = [i[0] for i in sim_scores[1:n_anime+1]]
        top_anime_titles = anime_data[
            [
                "name",
                "genre",
                "type",
                "episodes_category",
                "rating_category",
                "popularity_category",
            ]
        ].iloc[top_anime_indices]

        # Add similarity score to the dataframe
        top_anime_titles["similarity_score"] = [i[1] for i in sim_scores[1:n_anime+1]]
        return top_anime_titles
    except:
        return "Anime not found or an error occurred."

"""#### Content Based Filtering Result"""

# String to be searched in start of string
search = "Log Horizon"

# Search anime in the dataframe
found_anime = find_anime(search, df_anime)
found_anime

input_anime_title = "Log Horizon"

print("Recommendations for", input_anime_title + ":")
input_anime_info = df_anime[
    [
        "name",
        "genre",
        "type",
        "episodes_category",
        "rating_category",
        "popularity_category",
    ]
].loc[df_anime["name"] == input_anime_title]
print(input_anime_info.to_string(index=False))
print()

recommendations = get_cbf_recommendations(input_anime_title, cosine_sim, df_anime, 10)
recommendations

"""### Collaborative Filtering"""

from scipy.sparse import csr_matrix
from sklearn.neighbors import NearestNeighbors

anime_matrix = csr_matrix(anime_pivot.values)

model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute')
model_knn.fit(anime_matrix)

def find_anime_index(title, anime_pivot):
    return anime_pivot.index.get_loc(title)

def get_cf_recommendations(query_index, anime_pivot=anime_pivot, model_knn=model_knn, anime_data=df_anime, n_anime=5):
    distances, indices = model_knn.kneighbors(anime_pivot.iloc[query_index,:].values.reshape(1, -1), n_neighbors = n_anime+1)
    recommendations = []
    for i in range(1, len(distances.flatten())):
        anime_name = anime_pivot.index[indices.flatten()[i]]
        anime_info = anime_data[anime_data['name'] == anime_name].iloc[0]
        recommendations.append({
            'name': anime_info['name'],
            'genre': anime_info['genre'],
            'type': anime_info['type'],
            'episodes_category': anime_info['episodes_category'],
            'rating_category': anime_info['rating_category'],
            'popularity_category': anime_info['popularity_category'],
            'similarity_distance': distances.flatten()[i]
        })
    return pd.DataFrame(recommendations)

anime_name = "Log Horizon"
query_index = find_anime_index(anime_name, anime_pivot)
recommendations_df = get_cf_recommendations(query_index, anime_pivot, model_knn, df_anime, 10)

print("Recommendations for", anime_name + ":")
input_anime_info = df_anime[
    [
        "name",
        "genre",
        "type",
        "episodes_category",
        "rating_category",
        "popularity_category",
    ]
].loc[df_anime["name"] == input_anime_title]
print(input_anime_info.to_string(index=False))
print()

recommendations_df

"""## Evaluation"""

def evaluate_precision(relevant_items):
    """
    Evaluasi precision berdasarkan relevansi item yang direkomendasikan.

    Parameters:
    relevant_items (list): Daftar nilai relevansi item yang direkomendasikan.
                           1: relevan, 0: tidak relevan.

    Returns:
    float: Precision dari rekomendasi.
    """
    total_relevant = sum(relevant_items)
    total_recommended = len(relevant_items)
    precision = total_relevant / total_recommended if total_recommended > 0 else 0
    return precision

# Contoh penggunaan
relevant_items = [1, 0, 1, 1, 0]  # Contoh penilaian relevansi item yang direkomendasikan
precision = evaluate_precision(relevant_items)
print("Precision:", precision)

import numpy as np

def calculate_dcg(scores, k):
    dcg = 0
    for i in range(1, k+1):
        dcg += scores[i-1] / np.log2(i + 1)
    return dcg

def calculate_idcg(scores, k):
    scores_sorted = sorted(scores, reverse=True)
    idcg = calculate_dcg(scores_sorted, k)
    return idcg

def calculate_ndcg(scores, k):
    dcg = calculate_dcg(scores, k)
    idcg = calculate_idcg(scores, k)
    if idcg == 0:
        return 0
    return dcg / idcg

# Contoh penggunaan
scores = [10, 8, 7, 9, 5]  # Skor subjektif relevansi item yang direkomendasikan
k = len(scores)  # Jumlah item yang dievaluasi (misalnya, panjang dari skor)
ndcg = calculate_ndcg(scores, k)
print("NDCG:", ndcg)

"""### Content-Based Filtering"""

input_anime_title = "Log Horizon"

print("Recommendations for", input_anime_title + ":")
input_anime_info = df_anime[
    [
        "name",
        "genre",
        "type",
        "episodes_category",
        "rating_category",
        "popularity_category",
    ]
].loc[df_anime["name"] == input_anime_title]
print(input_anime_info.to_string(index=False))
print()

recommendations = get_cbf_recommendations(input_anime_title, cosine_sim, df_anime, 5)
recommendations

df_cbf_eval = recommendations[["name", "similarity_score"]].copy()

# memberikan relevansi pada item (1 or 0) untuk precision
df_cbf_eval["is_relevance"] = [1, 1, 1, 1, 0]

# memberikan score relevansi (1-5) untuk ndcg
df_cbf_eval["relevance_score"] = [5, 3, 3, 4, 1]

df_cbf_eval

# menghitung precision
precision = evaluate_precision(df_cbf_eval["is_relevance"])
print("Precision:", precision)

# menghitung ndcg
ndcg = calculate_ndcg(df_cbf_eval["relevance_score"].values, len(df_cbf_eval["relevance_score"].values))
print("NDCG:", ndcg)

"""### Collaborative Filtering"""

anime_name = "Log Horizon"
query_index = find_anime_index(anime_name, anime_pivot)
recommendations_df = get_cf_recommendations(query_index, anime_pivot, model_knn, df_anime, 5)

print("Recommendations for", anime_name + ":")
input_anime_info = df_anime[
    [
        "name",
        "genre",
        "type",
        "episodes_category",
        "rating_category",
        "popularity_category",
    ]
].loc[df_anime["name"] == input_anime_title]
print(input_anime_info.to_string(index=False))
print()

recommendations_df

df_cf_eval = recommendations_df[["name", "similarity_distance"]].copy()

# memberikan relevansi pada item (1 or 0) untuk precision
df_cf_eval["is_relevance"] = [1, 1, 1, 0, 0]

# memberikan score relevansi (1-5) untuk ndcg
df_cf_eval["relevance_score"] = [5, 4, 4, 1, 2]

df_cf_eval

# menghitung precision
precision = evaluate_precision(df_cf_eval["is_relevance"])
print("Precision:", precision)

# menghitung ndcg
ndcg = calculate_ndcg(df_cf_eval["relevance_score"].values, len(df_cf_eval["relevance_score"].values))
print("NDCG:", ndcg)